{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q-Learning_Taxi.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNvdLxIFJz6HkmKTzplOZEz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"DBtoxiwDuSOv","colab_type":"code","outputId":"a7737d85-3b8e-4911-f347-71989157dce5","executionInfo":{"status":"ok","timestamp":1584875036303,"user_tz":-60,"elapsed":4686,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!pip install cmake 'gym[atari]' scipy"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n","Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.17.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.18.2)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n","Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.2.6)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (7.0.0)\n","Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.1.2.30)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SVW6pwr89dMq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import gym\n","import random\n","\n","from time import sleep\n","from IPython.display import clear_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_VVnO1R-WgI","colab_type":"code","colab":{}},"source":["def random_actions(frames):\n","  env.s = 328  # set environment to illustration's state\n","\n","  epochs = 0\n","  penalties, reward = 0, 0\n","\n","  done = False\n","\n","  while not done:\n","      action = env.action_space.sample()\n","      state, reward, done, info = env.step(action)\n","\n","      if reward == -10:\n","          penalties += 1\n","      \n","      # Put each rendered frame into dict for animation\n","      frames.append({\n","          'frame': env.render(mode='ansi'),\n","          'state': state,\n","          'action': action,\n","          'reward': reward\n","          }\n","      )\n","\n","      epochs += 1\n","      \n","      \n","  print(\"Timesteps taken: {}\".format(epochs))\n","  print(\"Penalties incurred: {}\".format(penalties))\n","\n","def print_frames(frames):\n","  for i, frame in enumerate(frames):\n","      clear_output(wait=True)\n","      print(frame['frame'])\n","      print(f\"Timestep: {i + 1}\")\n","      print(f\"State: {frame['state']}\")\n","      print(f\"Action: {frame['action']}\")\n","      print(f\"Reward: {frame['reward']}\")\n","      if (i == 29):\n","        print('Force break!')\n","        break\n","      sleep(.5)\n","\n","def training_agent():\n","  %%time\n","\n","  # Hyperparameters\n","  alpha = 0.1\n","  gamma = 0.6\n","  epsilon = 0.1\n","\n","  # For plotting metrics\n","  all_epochs = []\n","  all_penalties = []\n","\n","  for i in range(1, 100001):\n","      state = env.reset()\n","\n","      epochs, penalties, reward, = 0, 0, 0\n","      done = False\n","      \n","      while not done:\n","          if random.uniform(0, 1) < epsilon:\n","              action = env.action_space.sample() # Explore action space\n","          else:\n","              action = np.argmax(q_table[state]) # Exploit learned values\n","\n","          next_state, reward, done, info = env.step(action) \n","          \n","          old_value = q_table[state, action]\n","          next_max = np.max(q_table[next_state])\n","          \n","          new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n","          q_table[state, action] = new_value\n","\n","          if reward == -10:\n","              penalties += 1\n","\n","          state = next_state\n","          epochs += 1\n","          \n","      if i % 100 == 0:\n","          clear_output(wait=True)\n","          print(f\"Episode: {i}\")\n","\n","  print(\"Training finished.\\n\")  \n","\n","def evaluate_agents():\n","  total_epochs, total_penalties = 0, 0\n","  episodes = 100\n","\n","  for _ in range(episodes):\n","      state = env.reset()\n","      epochs, penalties, reward = 0, 0, 0\n","      \n","      done = False\n","      \n","      while not done:\n","          action = np.argmax(q_table[state])\n","          state, reward, done, info = env.step(action)\n","\n","          if reward == -10:\n","              penalties += 1\n","\n","          epochs += 1\n","\n","      total_penalties += penalties\n","      total_epochs += epochs\n","\n","  print(f\"Results after {episodes} episodes:\")\n","  print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n","  print(f\"Average penalties per episode: {total_penalties / episodes}\")\n","\n","def evaluate_agent(frames):\n","    state = env.reset()\n","    reward = 0    \n","    done = False\n","    \n","    while not done:\n","        action = np.argmax(q_table[state])\n","        state, reward, done, info = env.step(action)\n","\n","        frames.append({\n","          'frame': env.render(mode='ansi'),\n","          'state': state,\n","          'action': action,\n","          'reward': reward\n","          }\n","      )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5MnRuEpudkm","colab_type":"code","outputId":"36176dbe-4a5b-489c-f1f2-8437b4b9a44b","executionInfo":{"status":"ok","timestamp":1584874871821,"user_tz":-60,"elapsed":1267,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["env = gym.make(\"Taxi-v3\").env\n","env.render()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+---------+\n","|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c0pc4bDOuiiz","colab_type":"code","outputId":"31f52466-7cd0-4046-da52-88f63f8443ba","executionInfo":{"status":"ok","timestamp":1584874873206,"user_tz":-60,"elapsed":460,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["env.reset()\n","env.render()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["+---------+\n","|\u001b[35mR\u001b[0m: |\u001b[43m \u001b[0m: :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8BwSxnmduzMH","colab_type":"code","outputId":"709edd5c-8a2c-4c74-bf02-588ec78f7d4e","executionInfo":{"status":"ok","timestamp":1584874876290,"user_tz":-60,"elapsed":472,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n","print(\"State:\", state)\n","\n","env.s = state\n","env.render()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["State: 328\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| |\u001b[43m \u001b[0m: | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KG_jVYLtwkOS","colab_type":"code","outputId":"f5805deb-f5aa-4218-ecca-4df45f019bb1","executionInfo":{"status":"ok","timestamp":1584874880291,"user_tz":-60,"elapsed":465,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["#This dictionary has the structure {action: [(probability, nextstate, reward, done)]}.\n","#The 0-5 corresponds to the actions (south, north, east, west, pickup, dropoff)\n","\n","env.P[328] "],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [(1.0, 428, -1, False)],\n"," 1: [(1.0, 228, -1, False)],\n"," 2: [(1.0, 348, -1, False)],\n"," 3: [(1.0, 328, -1, False)],\n"," 4: [(1.0, 328, -10, False)],\n"," 5: [(1.0, 328, -10, False)]}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"k7K89wKZ0FNG","colab_type":"code","outputId":"6389cd94-f442-4f67-cad6-6aaac94e4911","executionInfo":{"status":"ok","timestamp":1584875843256,"user_tz":-60,"elapsed":451,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["frames = [] # for animation\n","random_actions(frames)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Timesteps taken: 461\n","Penalties incurred: 158\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdvSn6pT0Gf3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"1973eff0-232d-4965-ab01-7aec3e74db57","executionInfo":{"status":"ok","timestamp":1584875859598,"user_tz":-60,"elapsed":10,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}}},"source":["print_frames(frames)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| |\u001b[43m \u001b[0m: | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","\n","Timestep: 30\n","State: 328\n","Action: 3\n","Reward: -1\n","Force break!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ubbZ8630pKv","colab_type":"code","outputId":"8dc88726-ceea-4139-a842-1bc2f80dd7c1","executionInfo":{"status":"ok","timestamp":1584875310496,"user_tz":-60,"elapsed":202,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["q_table = np.zeros([env.observation_space.n, env.action_space.n])\n","training_agent()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Episode: 100000\n","Training finished.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IMAd2RHy-set","colab_type":"code","outputId":"787887fd-f3d1-4117-dc2c-d45bddc83d2c","executionInfo":{"status":"ok","timestamp":1584875310499,"user_tz":-60,"elapsed":49518,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["q_table[328]"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ -2.41479814,  -2.27325184,  -2.40153538,  -2.36140151,\n","       -11.20432524, -11.03716745])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"HvWMi0Ov-_jF","colab_type":"code","outputId":"ffa62606-468f-4cd0-8be0-fe1130952aab","executionInfo":{"status":"ok","timestamp":1584875310500,"user_tz":-60,"elapsed":48964,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.max(q_table[328])"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-2.273251840000004"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"Q5CDTW87_gu1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"b211cec2-db91-4280-f456-30e239425d7a","executionInfo":{"status":"ok","timestamp":1584875311270,"user_tz":-60,"elapsed":426,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}}},"source":["evaluate_agents()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Results after 100 episodes:\n","Average timesteps per episode: 12.65\n","Average penalties per episode: 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0XCaSMh07XrQ","colab_type":"code","colab":{}},"source":["frames = []\n","evaluate_agent(frames)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcgsCZJ88qYQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"ac17bd09-090e-41d6-ae46-e7858cd27d5d","executionInfo":{"status":"ok","timestamp":1584875638174,"user_tz":-60,"elapsed":456,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}}},"source":["print_frames(frames)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["+---------+\n","|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (Dropoff)\n","\n","Timestep: 12\n","State: 0\n","Action: 5\n","Reward: 20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K23xyMDz8sbi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}